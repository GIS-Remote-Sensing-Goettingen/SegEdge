{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256cb4fa230409d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7336e9630b478e88eff931988e8668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='images/1084-1389.tif', description='GeoTIFF:', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAMWCAYAAAB2gvApAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEFJJREFUeJzt18EJACAQwDB1/53PJQqCJBP02z0zswAAAELndQAAAPAfowEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAA5owEAAOSMBgAAkDMaAABAzmgAAAC5C6UxCigD3wAaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%widget\n",
    "# Interactive SAM2 segmentation in a notebook (points & boxes)\n",
    "# ------------------------------------------------------------\n",
    "# Requirements (first time):\n",
    "#   pip install transformers accelerate timm torch torchvision tifffile pillow ipywidgets matplotlib scipy\n",
    "#   jupyter nbextension enable --py widgetsnbextension   # (Classic Notebook)\n",
    "# If using JupyterLab ≥3, widgets should work out of the box.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import Sam2Model, Sam2Processor\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from ipywidgets import (\n",
    "    HBox, VBox, Button, ToggleButtons, BoundedIntText, FloatSlider, Text, Dropdown,\n",
    "    HTML, Checkbox\n",
    ")\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities: IO + preprocessing\n",
    "# -----------------------------\n",
    "\n",
    "def load_multispectral(path: Path) -> np.ndarray:\n",
    "    arr = tifffile.imread(str(path))\n",
    "    if arr.ndim == 2:\n",
    "        arr = arr[np.newaxis, ...]\n",
    "    if arr.shape[0] < arr.shape[-1]:\n",
    "        # (C, H, W)\n",
    "        return arr.astype(np.float32)\n",
    "    # (H, W, C) -> (C, H, W)\n",
    "    return np.transpose(arr, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "def stretch_channel(ch: np.ndarray) -> np.ndarray:\n",
    "    lo, hi = np.percentile(ch, (2, 98))\n",
    "    if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
    "        denom = (np.nanmax(ch) or 1.0)\n",
    "        return np.clip(ch / denom, 0.0, 1.0)\n",
    "    return np.clip((ch - lo) / (hi - lo), 0.0, 1.0)\n",
    "\n",
    "def build_rgb_composite(ms: np.ndarray, band_indices_1based: List[int]) -> np.ndarray:\n",
    "    bands = []\n",
    "    for idx in band_indices_1based:\n",
    "        if not (1 <= idx <= ms.shape[0]):\n",
    "            raise ValueError(f\"Band {idx} out of range 1..{ms.shape[0]}\")\n",
    "        bands.append(stretch_channel(ms[idx - 1]))\n",
    "    comp = np.stack(bands, axis=0)  # (3,H,W) float in [0,1]\n",
    "    return np.transpose((comp * 255.0).astype(np.uint8), (1, 2, 0))  # (H,W,3) uint8\n",
    "\n",
    "# Optional: a light vegetation index used only when \"use veg seeding\" is enabled.\n",
    "def vegetation_index_from_rgb_uint8(rgb_uint8: np.ndarray) -> np.ndarray:\n",
    "    r = rgb_uint8[..., 0].astype(np.float32) / 255.0\n",
    "    g = rgb_uint8[..., 1].astype(np.float32) / 255.0\n",
    "    b = rgb_uint8[..., 2].astype(np.float32) / 255.0\n",
    "    exg = 2.0 * g - r - b\n",
    "    exg = (exg - np.nanmin(exg)) / (np.nanmax(exg) - np.nanmin(exg) + 1e-6)\n",
    "    return np.nan_to_num(exg, nan=0.0)\n",
    "\n",
    "# -----------------------------\n",
    "# SAM2 glue\n",
    "# -----------------------------\n",
    "\n",
    "def select_best_masks(post_masks: torch.Tensor, iou_scores: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    post_masks: (num_objects, num_masks, H, W) bool\n",
    "    iou_scores: (num_objects, num_masks)\n",
    "    returns: (H, W) bool combined\n",
    "    \"\"\"\n",
    "    if post_masks.shape[0] == 0:\n",
    "        raise ValueError(\"SAM2 returned no masks.\")\n",
    "    best = []\n",
    "    for o in range(post_masks.shape[0]):\n",
    "        best_idx = int(torch.argmax(iou_scores[o]).item())\n",
    "        best.append(post_masks[o, best_idx])\n",
    "    return torch.stack(best, dim=0).any(dim=0)\n",
    "\n",
    "# -----------------------------\n",
    "# Prompts storage (interactive)\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class ObjPrompts:\n",
    "    points: List[List[float]] = field(default_factory=list)   # [[x,y], ...]\n",
    "    labels: List[int] = field(default_factory=list)           # [1/0, ...]\n",
    "    box: Optional[List[float]] = None                         # [x0,y0,x1,y1] optional\n",
    "\n",
    "    def add_point(self, x: float, y: float, label: int):\n",
    "        self.points.append([float(x), float(y)])\n",
    "        self.labels.append(int(label))\n",
    "\n",
    "    def set_box(self, x0: float, y0: float, x1: float, y1: float):\n",
    "        self.box = [float(min(x0,x1)), float(min(y0,y1)), float(max(x0,x1)), float(max(y0,y1))]\n",
    "\n",
    "class PromptManager:\n",
    "    def __init__(self):\n",
    "        self.by_obj: Dict[int, ObjPrompts] = {}\n",
    "\n",
    "    def obj(self, oid: int) -> ObjPrompts:\n",
    "        if oid not in self.by_obj:\n",
    "            self.by_obj[oid] = ObjPrompts()\n",
    "        return self.by_obj[oid]\n",
    "\n",
    "    def to_sam2(self) -> Tuple[List[List[List[float]]], List[List[int]], Optional[List[List[float]]]]:\n",
    "        if not self.by_obj:\n",
    "            return [], [], None\n",
    "        obj_ids = sorted(self.by_obj.keys())\n",
    "        input_points: List[List[List[float]]] = []\n",
    "        input_labels: List[List[int]] = []\n",
    "        input_boxes: List[List[float]] = []\n",
    "        any_box = False\n",
    "        for oid in obj_ids:\n",
    "            group = self.by_obj[oid]\n",
    "            # SAM2 expects at least one point per object; if box-only, inject a dummy positive point\n",
    "            if not group.points and group.box is not None:\n",
    "                cx = (group.box[0] + group.box[2]) * 0.5\n",
    "                cy = (group.box[1] + group.box[3]) * 0.5\n",
    "                group.add_point(cx, cy, 1)\n",
    "            input_points.append(group.points)\n",
    "            input_labels.append(group.labels)\n",
    "            if group.box is not None:\n",
    "                input_boxes.append(group.box)\n",
    "                any_box = True\n",
    "            else:\n",
    "                input_boxes.append([0,0,0,0])\n",
    "        return input_points, input_labels, (input_boxes if any_box else None)\n",
    "\n",
    "    def clear(self):\n",
    "        self.by_obj.clear()\n",
    "\n",
    "    def remove_last(self):\n",
    "        # remove last item (point preferred; else box) of currently highest obj id\n",
    "        if not self.by_obj:\n",
    "            return\n",
    "        oid = sorted(self.by_obj.keys())[-1]\n",
    "        g = self.by_obj[oid]\n",
    "        if g.points:\n",
    "            g.points.pop()\n",
    "            g.labels.pop()\n",
    "        elif g.box is not None:\n",
    "            g.box = None\n",
    "        if not g.points and g.box is None:\n",
    "            self.by_obj.pop(oid, None)\n",
    "\n",
    "# -----------------------------\n",
    "# Interactive UI\n",
    "# -----------------------------\n",
    "\n",
    "# Widgets\n",
    "t_path = Text(description=\"GeoTIFF:\", value=\"images/1084-1389.tif\", layout=dict(width=\"400px\"))\n",
    "t_bands = Text(description=\"Bands:\", value=\"2,4,6\", layout=dict(width=\"200px\"), placeholder=\"R,G,B (1-based)\")\n",
    "d_model = Dropdown(\n",
    "    description=\"Model:\",\n",
    "    options=[\n",
    "        (\"sam2.1-hiera-tiny\", \"facebook/sam2.1-hiera-tiny\"),\n",
    "        (\"sam2.1-hiera-small\", \"facebook/sam2.1-hiera-small\"),\n",
    "        (\"sam2.1-hiera-base\", \"facebook/sam2.1-hiera-base\"),\n",
    "        (\"sam2.1-hiera-large\", \"facebook/sam2.1-hiera-large\"),\n",
    "    ],\n",
    "    value=\"facebook/sam2.1-hiera-tiny\",\n",
    "    layout=dict(width=\"260px\")\n",
    ")\n",
    "d_device = Dropdown(description=\"Device:\", options=[\"auto\",\"cuda\",\"cpu\"], value=\"auto\", layout=dict(width=\"140px\"))\n",
    "\n",
    "btn_load = Button(description=\"Load image\", button_style=\"primary\")\n",
    "btn_run  = Button(description=\"Run segmentation\")\n",
    "btn_undo = Button(description=\"Undo last\")\n",
    "btn_clear= Button(description=\"Clear prompts\")\n",
    "btn_save = Button(description=\"Save outputs\")\n",
    "\n",
    "alpha = FloatSlider(description=\"Overlay α\", value=0.6, min=0.0, max=1.0, step=0.05, readout_format=\".2f\", layout=dict(width=\"300px\"))\n",
    "use_veg = Checkbox(value=False, description=\"Use vegetation seeding (fallback)\")\n",
    "min_area = BoundedIntText(value=5_000, min=0, max=10_000_000, step=100, description=\"Min area px:\")\n",
    "\n",
    "mode = ToggleButtons(options=[(\"Points\",\"points\"),(\"Box (drag)\",\"box\")], description=\"Mode:\")\n",
    "label_choice = ToggleButtons(options=[(\"Positive\",\"+1\"),(\"Negative\",\"0\")], description=\"Label:\")\n",
    "obj_id = BoundedIntText(value=0, min=0, max=9999, step=1, description=\"Object ID:\")\n",
    "\n",
    "status = HTML(value=\"<b>Status:</b> idle\")\n",
    "\n",
    "controls_top = HBox([t_path, t_bands, d_model, d_device, btn_load])\n",
    "controls_mid = HBox([mode, label_choice, obj_id, alpha, min_area, use_veg])\n",
    "controls_bot = HBox([btn_run, btn_undo, btn_clear, btn_save, status])\n",
    "\n",
    "display(VBox([controls_top, controls_mid, controls_bot]))\n",
    "\n",
    "# Figure\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.set_axis_off()\n",
    "fig.canvas.header_visible = False if hasattr(fig.canvas, \"header_visible\") else None\n",
    "\n",
    "# State\n",
    "image_uint8: Optional[np.ndarray] = None\n",
    "ms_stack: Optional[np.ndarray] = None\n",
    "mask_bool: Optional[np.ndarray] = None\n",
    "prompts = PromptManager()\n",
    "\n",
    "scatter_pos = None\n",
    "scatter_neg = None\n",
    "box_artist: Optional[Rectangle] = None\n",
    "dragging = False\n",
    "drag_start = (0.0, 0.0)\n",
    "\n",
    "# Persisted model/processor\n",
    "_model: Optional[Sam2Model] = None\n",
    "_processor: Optional[Sam2Processor] = None\n",
    "_device: Optional[torch.device] = None\n",
    "\n",
    "def log(msg: str):\n",
    "    status.value = f\"<b>Status:</b> {msg}\"\n",
    "\n",
    "def load_model(model_id: str, device_pref: str):\n",
    "    global _model, _processor, _device\n",
    "    if _model is not None and getattr(_model, 'model_id', None) == model_id and _device is not None:\n",
    "        # Reuse loaded model\n",
    "        devname = str(_device)\n",
    "        log(f\"model already loaded on {devname}\")\n",
    "        return\n",
    "    log(f\"loading {model_id} …\")\n",
    "    processor = Sam2Processor.from_pretrained(model_id)\n",
    "    model = Sam2Model.from_pretrained(model_id)\n",
    "    if device_pref == \"auto\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if (device_pref == \"cuda\" and torch.cuda.is_available()) else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    _model = model\n",
    "    _model.model_id = model_id  # type: ignore[attr-defined]\n",
    "    _processor = processor\n",
    "    _device = device\n",
    "    log(f\"loaded on {device}\")\n",
    "\n",
    "def redraw():\n",
    "    \"\"\"Redraw image, points, boxes, and overlay.\"\"\"\n",
    "    global scatter_pos, scatter_neg, box_artist, image_uint8, mask_bool\n",
    "    ax.clear()\n",
    "    ax.set_axis_off()\n",
    "    if image_uint8 is None:\n",
    "        fig.canvas.draw_idle()\n",
    "        return\n",
    "    h, w, _ = image_uint8.shape\n",
    "    ax.imshow(image_uint8, origin=\"upper\", interpolation=\"nearest\")\n",
    "    # Overlay mask\n",
    "    if mask_bool is not None and mask_bool.any():\n",
    "        overlay = image_uint8.copy()\n",
    "        color = np.array([46, 204, 113], dtype=np.float32)  # pleasant green\n",
    "        mm = mask_bool.astype(bool)\n",
    "        blended = (1.0 - alpha.value) * overlay[mm].astype(np.float32) + alpha.value * color\n",
    "        overlay[mm] = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "        ax.imshow(overlay, origin=\"upper\", interpolation=\"nearest\")\n",
    "    # Points\n",
    "    pos_xy = []\n",
    "    neg_xy = []\n",
    "    for oid, grp in prompts.by_obj.items():\n",
    "        for (x,y), lab in zip(grp.points, grp.labels):\n",
    "            (pos_xy if lab == 1 else neg_xy).append((x,y))\n",
    "    if pos_xy:\n",
    "        xs, ys = zip(*pos_xy)\n",
    "        scatter_pos = ax.scatter(xs, ys, s=40, marker='o', edgecolor='white', facecolor='lime', linewidths=0.75)\n",
    "    if neg_xy:\n",
    "        xs, ys = zip(*neg_xy)\n",
    "        scatter_neg = ax.scatter(xs, ys, s=40, marker='x', c='red', linewidths=1.5)\n",
    "    # Box (only show last box for current obj id)\n",
    "    cur = prompts.by_obj.get(obj_id.value)\n",
    "    if cur and cur.box is not None:\n",
    "        x0,y0,x1,y1 = cur.box\n",
    "        box_artist = Rectangle((x0,y0), x1-x0, y1-y0, fill=False, linewidth=2, edgecolor='cyan')\n",
    "        ax.add_patch(box_artist)\n",
    "    ax.set_xlim(0, w)\n",
    "    ax.set_ylim(h, 0)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_press(event):\n",
    "    global dragging, drag_start\n",
    "    if image_uint8 is None or event.inaxes != ax:\n",
    "        return\n",
    "    x, y = event.xdata, event.ydata\n",
    "    if x is None or y is None:\n",
    "        return\n",
    "    if mode.value == \"points\":\n",
    "        lab = 1 if label_choice.value == \"+1\" else 0\n",
    "        prompts.obj(obj_id.value).add_point(x, y, lab)\n",
    "        log(f\"added {'pos' if lab==1 else 'neg'} point at ({int(x)}, {int(y)}) to obj {obj_id.value}\")\n",
    "        redraw()\n",
    "    else:\n",
    "        dragging = True\n",
    "        drag_start = (x, y)\n",
    "        # show a 1x1 rect until motion\n",
    "        prompts.obj(obj_id.value).set_box(x, y, x, y)\n",
    "        redraw()\n",
    "\n",
    "def on_motion(event):\n",
    "    global dragging\n",
    "    if not dragging or event.inaxes != ax:\n",
    "        return\n",
    "    x, y = event.xdata, event.ydata\n",
    "    if x is None or y is None:\n",
    "        return\n",
    "    sx, sy = drag_start\n",
    "    prompts.obj(obj_id.value).set_box(sx, sy, x, y)\n",
    "    redraw()\n",
    "\n",
    "def on_release(event):\n",
    "    global dragging\n",
    "    if not dragging:\n",
    "        return\n",
    "    dragging = False\n",
    "    x, y = event.xdata, event.ydata\n",
    "    if x is None or y is None:\n",
    "        return\n",
    "    sx, sy = drag_start\n",
    "    prompts.obj(obj_id.value).set_box(sx, sy, x, y)\n",
    "    log(f\"set box for obj {obj_id.value}: ({int(sx)},{int(sy)})–({int(x)},{int(y)})\")\n",
    "    redraw()\n",
    "\n",
    "cid_press = fig.canvas.mpl_connect('button_press_event', on_press)\n",
    "cid_motion = fig.canvas.mpl_connect('motion_notify_event', on_motion)\n",
    "cid_release= fig.canvas.mpl_connect('button_release_event', on_release)\n",
    "\n",
    "# -----------------------------\n",
    "# Actions\n",
    "# -----------------------------\n",
    "\n",
    "def do_load(_=None):\n",
    "    global ms_stack, image_uint8, mask_bool\n",
    "    try:\n",
    "        path = Path(t_path.value).expanduser()\n",
    "        if not path.exists():\n",
    "            log(\"file not found\")\n",
    "            return\n",
    "        ms_stack = load_multispectral(path)\n",
    "        bands = [int(s.strip()) for s in t_bands.value.split(\",\") if s.strip()]\n",
    "        if len(bands) != 3:\n",
    "            log(\"need exactly 3 bands (e.g. 2,4,6)\")\n",
    "            return\n",
    "        image_uint8 = build_rgb_composite(ms_stack, bands)\n",
    "        mask_bool = None\n",
    "        prompts.clear()\n",
    "        redraw()\n",
    "        log(f\"loaded image {path.name}  size={image_uint8.shape[1]}x{image_uint8.shape[0]}\")\n",
    "    except Exception as e:\n",
    "        log(f\"load error: {e}\")\n",
    "\n",
    "def compute_auto_prompts_from_veg(max_objects=50, min_area_px=250):\n",
    "    \"\"\"Optional fallback: seed positives by vegetation peaks, add small boxes.\"\"\"\n",
    "    if image_uint8 is None:\n",
    "        return\n",
    "    vi = vegetation_index_from_rgb_uint8(image_uint8)\n",
    "    thr = np.percentile(vi, 92)\n",
    "    candidate = ndi.binary_opening(vi > thr, structure=np.ones((3,3), bool))\n",
    "    labeled, n = ndi.label(candidate)\n",
    "    if n == 0:\n",
    "        return\n",
    "    sizes = ndi.sum(candidate, labeled, index=range(1, n+1))\n",
    "    order = np.argsort(sizes)[::-1]\n",
    "    h, w = vi.shape\n",
    "    prompts.clear()\n",
    "    taken = 0\n",
    "    for i in order:\n",
    "        sl = ndi.find_objects(labeled)[i]\n",
    "        if sl is None: continue\n",
    "        ys, xs = sl\n",
    "        y0,y1 = ys.start, ys.stop\n",
    "        x0,x1 = xs.start, xs.stop\n",
    "        cy = (y0+y1-1)/2.0\n",
    "        cx = (x0+x1-1)/2.0\n",
    "        area = (y1-y0)*(x1-x0)\n",
    "        if area < min_area_px:\n",
    "            continue\n",
    "        oid = taken\n",
    "        prompts.obj(oid).add_point(cx, cy, 1)\n",
    "        # pad a bit\n",
    "        pad = max(int(0.01*max(h,w)), 6)\n",
    "        prompts.obj(oid).set_box(x0-pad, y0-pad, x1+pad, y1+pad)\n",
    "        taken += 1\n",
    "        if taken >= max_objects:\n",
    "            break\n",
    "\n",
    "def do_run(_=None):\n",
    "    global mask_bool\n",
    "    if image_uint8 is None:\n",
    "        log(\"load an image first\")\n",
    "        return\n",
    "    try:\n",
    "        # Load model if needed\n",
    "        load_model(d_model.value, d_device.value)\n",
    "        assert _model is not None and _processor is not None and _device is not None\n",
    "\n",
    "        # Prepare prompts\n",
    "        in_pts, in_labs, in_boxes = prompts.to_sam2()\n",
    "        if not in_pts and use_veg.value:\n",
    "            compute_auto_prompts_from_veg()\n",
    "            in_pts, in_labs, in_boxes = prompts.to_sam2()\n",
    "        if not in_pts:\n",
    "            log(\"no prompts yet (add points or enable veg fallback)\")\n",
    "            return\n",
    "\n",
    "        image = Image.fromarray(image_uint8)\n",
    "        kwargs = dict(\n",
    "            images=image,\n",
    "            input_points=in_pts,\n",
    "            input_labels=in_labs,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        if in_boxes is not None:\n",
    "            kwargs[\"input_boxes\"] = in_boxes\n",
    "\n",
    "        inputs = _processor(**kwargs)\n",
    "        inputs = {k: v.to(_device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = _model(**inputs)\n",
    "\n",
    "        pred_masks = outputs.pred_masks.detach().to(\"cpu\")\n",
    "        iou_scores = outputs.iou_scores.detach().to(\"cpu\")\n",
    "        post_masks = _processor.post_process_masks(pred_masks, inputs[\"original_sizes\"])[0]  # (num_obj,num_masks,H,W) bool\n",
    "        best = select_best_masks(post_masks, iou_scores[0])  # (H,W) bool\n",
    "        mask_bool = best.cpu().numpy().astype(bool)\n",
    "\n",
    "        # Clean tiny speckles\n",
    "        if min_area.value > 0:\n",
    "            structure = np.ones((3,3), dtype=bool)\n",
    "            mb = ndi.binary_opening(mask_bool, structure=structure)\n",
    "            labeled, n = ndi.label(mb)\n",
    "            if n > 0:\n",
    "                sizes = ndi.sum(mb, labeled, index=range(1, n+1))\n",
    "                keep = np.zeros(n+1, dtype=bool)\n",
    "                keep[1:] = sizes >= min_area.value\n",
    "                mask_bool = keep[labeled]\n",
    "        redraw()\n",
    "        coverage = float(mask_bool.mean()*100.0) if mask_bool is not None else 0.0\n",
    "        log(f\"done. coverage={coverage:.2f}%\")\n",
    "    except Exception as e:\n",
    "        log(f\"inference error: {e}\")\n",
    "\n",
    "def do_undo(_=None):\n",
    "    prompts.remove_last()\n",
    "    log(\"undid last prompt/box\")\n",
    "    redraw()\n",
    "\n",
    "def do_clear(_=None):\n",
    "    global mask_bool\n",
    "    prompts.clear()\n",
    "    mask_bool = None\n",
    "    log(\"cleared prompts & mask\")\n",
    "    redraw()\n",
    "\n",
    "def do_save(_=None):\n",
    "    if image_uint8 is None or mask_bool is None:\n",
    "        log(\"nothing to save\")\n",
    "        return\n",
    "    out_dir = Path(\"../outputs\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # mask\n",
    "    mask_img = Image.fromarray((mask_bool.astype(np.uint8) * 255))\n",
    "    base = Path(t_path.value).stem\n",
    "    mask_path = out_dir / f\"{base}_interactive_mask.png\"\n",
    "    mask_img.save(mask_path)\n",
    "    # overlay\n",
    "    overlay = image_uint8.copy()\n",
    "    mm = mask_bool.astype(bool)\n",
    "    color = np.array([46, 204, 113], dtype=np.float32)\n",
    "    blended = (1.0 - alpha.value) * overlay[mm].astype(np.float32) + alpha.value * color\n",
    "    overlay[mm] = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "    overlay_path = out_dir / f\"{base}_interactive_overlay.png\"\n",
    "    Image.fromarray(overlay).save(overlay_path)\n",
    "    log(f\"saved: {mask_path.name}, {overlay_path.name} -> {out_dir.resolve()}\")\n",
    "\n",
    "# Wire buttons\n",
    "btn_load.on_click(do_load)\n",
    "btn_run.on_click(do_run)\n",
    "btn_undo.on_click(do_undo)\n",
    "btn_clear.on_click(do_clear)\n",
    "btn_save.on_click(do_save)\n",
    "\n",
    "redraw()\n",
    "log(\"ready. Load an image, then click to add prompts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab57a78-6d53-43a3-83f2-d55ee126d05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
